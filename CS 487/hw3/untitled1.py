# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UNftLLN8Opw24fvrk5Ku0LeBPIFlAajO
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow.keras
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image
from tensorflow.keras.utils import plot_model
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

epochs = 5
batch_size = 8
training_samples = 200
validation_samples = 400
img_width = 200
img_height = 200
channels = 3
input_shape = ( img_width, img_height, 3 )

train_data_dir = 'drive/MyDrive/Small_set_cats_vs_dogs/train'
validation_data_dir = 'drive/MyDrive/Small_set_cats_vs_dogs/val'
train_datagen = ImageDataGenerator(
    rescale = 1. / 255,
    shear_range = 0.4,
    zoom_range = 0.4,
    rotation_range = 20,
    width_shift_range = 0.4,
    height_shift_range = 0.4,
    horizontal_flip = True,
    vertical_flip = True,
    fill_mode = "nearest"
)

val_datagen = ImageDataGenerator( rescale = 1. / 255 )
print( "Training Images:" )
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size = ( img_width, img_height ),
    batch_size = batch_size,
    class_mode = "binary"
)

print( "Validation Images:" )
validation_generator = val_datagen.flow_from_directory(
    validation_data_dir,
    target_size = ( img_width, img_height ),
    batch_size = batch_size,
    class_mode = "binary"
)

test_data_dir = 'drive/MyDrive/Small_set_cats_vs_dogs/test'
test_datagen = ImageDataGenerator(
    rescale = 1. / 255,
    shear_range = 0.4,
    zoom_range = 0.4,
    rotation_range = 20,
    width_shift_range = 0.4,
    height_shift_range = 0.4,
    horizontal_flip = True,
    vertical_flip = True,
    fill_mode = "nearest"
)

# val_datagen = ImageDataGenerator( rescale = 1. / 255 )
print( "Testing Images:" )
test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size = ( img_width, img_height ),
    batch_size = batch_size,
    class_mode = "binary"
)

# print( "Validation Images:" )
# validation_generator = val_datagen.flow_from_directory(
#     validation_data_dir,
#     target_size = ( img_width, img_height ),
#     batch_size = batch_size,
#     class_mode = "binary"
# )

model = Sequential( name="sequential" )
model.add( Conv2D( 64, 3, padding="same" ) )
model.add( Conv2D( 64, 3, padding="same" ) )
model.add( MaxPooling2D( pool_size=(2, 2) ) )
model.add( Conv2D( 128, 3, padding="same" ) )
model.add( Conv2D( 128, 3, padding="same" ) )
model.add( MaxPooling2D( pool_size=(2, 2) ) )
model.add( Conv2D( 256, 3, padding="same" ) )
model.add( Conv2D( 256, 3, padding="same" ) )
model.add( MaxPooling2D( pool_size=(2, 2) ) )
model.add( Conv2D( 512, 3, padding="same" ) )
model.add( Conv2D( 512, 3, padding="same" ) )
model.add( Conv2D( 512, 3, padding="same" ) )
model.add( MaxPooling2D( pool_size=(2, 2) ) )
# model.add( Conv2D( 512, 3, padding="same" ) )
# model.add( Conv2D( 512, 3, padding="same" ) )
# model.add( Conv2D( 512, 3, padding="same" ) )
# model.add( MaxPooling2D( pool_size=(2, 2) ) )
model.add( Flatten() )
model.add( Dense( 100 ) )
model.add( Dense( 100 ) )
model.add( Dense( 1 ) )
model.add( Activation( "sigmoid" ) )

m = model( tf.ones( ( batch_size, img_width, img_height, 3 ) ) )

# model.summary()
# print( model.get_weights() )

model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=[ "accuracy" ]
)

model.fit( train_generator, batch_size=batch_size, epochs=epochs, steps_per_epoch=training_samples, validation_data=validation_generator, validation_steps=validation_samples, verbose=1 )

# score = model.evaluate( test_generator, batch_size=batch_size, epochs=epochs, steps_per_epoch=training_samples, verbose=1 )

# print( score )

model.summary()
print( model.get_weights() )

