\documentclass[ 12pt ]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{tikz}
\usepackage{listings}
\usepackage{enumerate}
\usepackage[margin=0.5in]{geometry}
\footskip = -0.75in
\lstset{
    tabsize=2
}

\begin{document}

% title page
\title{%
	Homework 7 \\
	\large CS 477 Analysis of Algorithims \\
	Section 1001}
\author{Landon Fox}
\date{April 28, 2020}
\maketitle
\newpage

\begin{itemize}
	% problem 1
	\item[] {\large 1)}
	Given any scheduling, the time required to complete the sequence of jobs
	can be represented as $f_i + \sum_{k=1}^i p_k$ for some $i$. We know that this
	must be greater than or equal to the last job completed; $f_n + \sum_{k=1}^n p_k$. Thus our
	solution does not appear to strongly dependent on $p_i$ rather we want to place
	the minimal $f_i$ terms at the end of the schedule. Let us attempt to create
	a greedy strategy that schedules the jobs with the maximal $f_i$ time first. \\

	\begin{center}
	\begin{lstlisting}
algorithm( f[ 1..n ], i[ 1..n ] )
	sort( f, i )
	return i
	\end{lstlisting}
	\end{center}

	This algorithm takes an input of an array $f$ which contains the time values
	required from the high performance computers. The array $i$ is parallel with
	$f$ such that the value in $f$ with index $j$ is corresponding to job $i_j$.
	The $sort$ function is any sorting algorithm that sorts two parallel arrays
	based on the values of the first input from greatest to least. The most costly
	procedure in the algorithm is the sorting, if we were to use quicksort then
	the average time complexity of would be $\Theta(nlgn)$. \\ \\

	Let us consider two algorithms for schedule creation; our greedy algorithm
	and another optimal solution. Let us now consider a schedule that contains
	only two jobs. This illustrates two possiblities $\{ f_i, f_j \}$ and
	$\{ f_j, f_i \}$. WLOG let's assume $f_i \geq f_j$, this implies that the
	first of the ordered sets is caused by our greedy algorithm. If the optimal
	algorithm produces the other, then it will result in nonoptimal time as a
	result of the first schedule's completion time in comparison to the second.
	$f_i \geq f_j \rightarrow f_i + p_i + p_j \geq f_j + p_i + p_j$. As a result
	we were able to pair two elements together, compare and permute them to
	find an optimal solution for $n=2$, for $n>2$ inductively we can use a similar
	argument by pairing two elements at a time to find an optimal completion time.
	This is possible because this process of permuting adjacent jobs does not affect
	other job's completion time. Thus our greedy algorithm of scheduling jobs from
	greatest to least in regard to $f$ holds the greedy choice property. \\ \\

	As stated before, a single choice in our greedy algorithm does not affect proceeding
	jobs thus if we have $n$ jobs we can use our greedy choice and then repeat the
	process for $n-1$ jobs. Thus our greedy algorithm has an optimal substructure.
	\newpage

	% problem 2
	\item[] {\large 2)}
	Given the start and finish times of a set of processes, we seek to find the
	minimal instances of time such that each process is recorded. Clearly we
	need to run our $process\_check$ during each process, let's attempt to create
	a greedy algorithm that finds the instance of time with the most active
	processes. \\

	\begin{center}
	\begin{lstlisting}
algorithm( s[ 1..n ], f[ 1..n ], t[] )
	sort( f, s )
	helper( s, f, t )

helper( s[ 1..n ], f[ 1..n ], t[] )
	if n > 0
		t.append( predecessor( f[ 1 ] ) )
		for i = n downto 1
			if s[ i ] <= f[ i ]
				s.remove( i )
				f.remove( i )
		helper( s, f, t )
	\end{lstlisting}
	\end{center}

	This algorithm takes three inputs; an array $s$ which contains the start
	times of all processes, $f$ a parallel array to $s$ which holds the finish
	times, and finally $t$ which will store the optimal solution. This algorithm
	makes use of a sorting algorithm similar to problem $1$ as it sorts parallel
	arrays only in respect to the values in the first input, however unlike problem
	$1$ this sorting function orders it from least to greatest. Finally the
	algorithm uses a helper function for recursion. The $helper$ function
	finds the first finishing time and appends the moment just before to our
	set of optimal times. Next it removes all processes that have been checked
	then continues with the rest of the unchecked processes. The most costly
	operation in our algorithm is the helper function which has $\Theta(n^2)$
	time complexity. \\ \\

	Let us consider two algorithms, our greedy algorithm and an optimal algorithm.
	In the interval between a new process starting and its ending, we know
	$process\_check$ must be called. Clearly there is a maximum amount of processes
	that occur in this interval, undoubtedly this occurs before the first ending of
	a process. Our greedy algorithm calls $process\_check$ right before this occurs,
	if the optimal algorithm did not, it would imply our greedy algorithm can improve
	upon it because it chooses the local maximum at any given choice. Thus our greedy
	algorithm holds the greedy choice property. \\ \\

	For $n$ processes our greedy algorithm looks at a given interval and chooses 
	the optimal choice then preforms the same choice for $n-1$ jobs, thus our
	algorithm holds optimal substructure.
	\newpage

	% problem 4
	\item[] {\large 4)}
	\begin{itemize}
		% problem 4a
		\item[] {\large 4a)}
		True, the two least frequent terms are always encoded with the same length
		with a single bit difference. If this were not true then that would imply
		that it would be more effiecient to place them higher on the optimal tree.
		A fallacy, the effieciency of the binary tree would worsen because it would
		have to access the more frequently accessed characters with more operations
		when searching the tree. \\

		% problem 4b
		\item[] {\large 4b)}
		True, the codeword's length of a more frequent character is always smaller
		than or equal to the codewordâ€™s length of a less frequent one. If this were
		not true it would imply that accessing more frequent characters with less
		operations would hinder the performance.

	\end{itemize}
\end{itemize}

\end{document}